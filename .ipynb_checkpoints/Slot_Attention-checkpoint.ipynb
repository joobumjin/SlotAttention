{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iTGnEyGT7m0s"
   },
   "outputs": [],
   "source": [
    "from absl import logging\n",
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import numpy as np\n",
    "import tensorflow.keras.layers as layers\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fTdux-_354b7"
   },
   "outputs": [],
   "source": [
    "\"\"\"Slot Attention model for object discovery and set prediction.\"\"\"\n",
    "\n",
    "class SlotAttention(layers.Layer):\n",
    "  \"\"\"Slot Attention module.\"\"\"\n",
    "\n",
    "  def __init__(self, num_iterations, num_slots, slot_size, mlp_hidden_size,\n",
    "               epsilon=1e-8):\n",
    "    \"\"\"Builds the Slot Attention module.\n",
    "    Args:\n",
    "      num_iterations: Number of iterations.\n",
    "      num_slots: Number of slots.\n",
    "      slot_size: Dimensionality of slot feature vectors.\n",
    "      mlp_hidden_size: Hidden layer size of MLP.\n",
    "      epsilon: Offset for attention coefficients before normalization.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self.num_iterations = num_iterations\n",
    "    self.num_slots = num_slots\n",
    "    self.slot_size = slot_size\n",
    "    self.mlp_hidden_size = mlp_hidden_size\n",
    "    self.epsilon = epsilon\n",
    "\n",
    "    self.norm_inputs = layers.LayerNormalization()\n",
    "    self.norm_slots = layers.LayerNormalization()\n",
    "    self.norm_mlp = layers.LayerNormalization()\n",
    "\n",
    "    # Parameters for Gaussian init (shared by all slots).   # Intialize slots randomly at first \n",
    "    self.slots_mu = self.add_weight(\n",
    "        initializer=\"glorot_uniform\",\n",
    "        shape=[1, 1, self.slot_size],   # slot_size: Dimensionality of slot feature vectors.\n",
    "        dtype=tf.float32,\n",
    "        name=\"slots_mu\")\n",
    "    self.slots_log_sigma = self.add_weight(\n",
    "        initializer=\"glorot_uniform\",\n",
    "        shape=[1, 1, self.slot_size],\n",
    "        dtype=tf.float32,\n",
    "        name=\"slots_log_sigma\")\n",
    "\n",
    "    # Linear maps for the attention module.\n",
    "    self.project_q = layers.Dense(self.slot_size, use_bias=False, name=\"q\")\n",
    "    self.project_k = layers.Dense(self.slot_size, use_bias=False, name=\"k\")\n",
    "    self.project_v = layers.Dense(self.slot_size, use_bias=False, name=\"v\")\n",
    "\n",
    "    # Slot update functions.\n",
    "    self.gru = layers.GRUCell(self.slot_size)\n",
    "    self.mlp = tf.keras.Sequential([\n",
    "        layers.Dense(self.mlp_hidden_size, activation=\"relu\"),\n",
    "        layers.Dense(self.slot_size)\n",
    "    ], name=\"mlp\")\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # `inputs` has shape [batch_size, num_inputs, inputs_size].\n",
    "    inputs = self.norm_inputs(inputs)  # Apply layer norm to the input.\n",
    "    k = self.project_k(inputs)  # Shape: [batch_size, num_inputs, slot_size].  # create key vectors (based on inputs)\n",
    "    v = self.project_v(inputs)  # Shape: [batch_size, num_inputs, slot_size].  # create value vectors (based on inputs)\n",
    "\n",
    "    # Initialize the slots. Shape: [batch_size, num_slots, slot_size].\n",
    "    slots = self.slots_mu + tf.exp(self.slots_log_sigma) * tf.random.normal(\n",
    "        [tf.shape(inputs)[0], self.num_slots, self.slot_size])  # size: [batch_size, num_slots, slot_size]\n",
    "\n",
    "    # Multiple rounds of attention.\n",
    "    for _ in range(self.num_iterations):\n",
    "      slots_prev = slots\n",
    "      slots = self.norm_slots(slots)\n",
    "\n",
    "      # Attention.\n",
    "      q = self.project_q(slots)  # Shape: [batch_size, num_slots, slot_size].  # create query vectors (based on slots)\n",
    "      q *= self.slot_size ** -0.5  # Normalization.\n",
    "      attn_logits = tf.keras.backend.batch_dot(k, q, axes=-1) # Batchwise dot product.\n",
    "      attn = tf.nn.softmax(attn_logits, axis=-1)\n",
    "      # `attn` has shape: [batch_size, num_inputs, num_slots]. \n",
    "      # attn represents how much attention each slot should pay to the features \n",
    "\n",
    "      # Weigted mean.\n",
    "      attn += self.epsilon\n",
    "      attn /= tf.reduce_sum(attn, axis=-2, keepdims=True) # summation; sum across the batch_size \n",
    "      updates = tf.keras.backend.batch_dot(attn, v, axes=-2)\n",
    "      # `updates` has shape: [batch_size, num_slots, slot_size].\n",
    "\n",
    "      # Slot update.\n",
    "      slots, _ = self.gru(updates, [slots_prev])   # output after gru has shape: [batch_size, num_slots, slot_size]\n",
    "      slots += self.mlp(self.norm_mlp(slots))      # # output after mlp has shape: [batch_size, num_slots, slot_size]\n",
    "\n",
    "    return slots\n",
    "\n",
    "\n",
    "def spatial_broadcast(slots, resolution):\n",
    "  \"\"\"Broadcast slot features to a 2D grid and collapse slot dimension.\"\"\"\n",
    "  # `slots` has shape: [batch_size, num_slots, slot_size].\n",
    "  slots = tf.reshape(slots, [-1, slots.shape[-1]])[:, None, None, :]\n",
    "  grid = tf.tile(slots, [1, resolution[0], resolution[1], 1])   # this operation creates a new tensor by replicating input multiples times\n",
    "  # `grid` has shape: [batch_size*num_slots, width, height, slot_size].\n",
    "  return grid\n",
    "\n",
    "\n",
    "def spatial_flatten(x):\n",
    "  return tf.reshape(x, [-1, x.shape[1] * x.shape[2], x.shape[-1]])\n",
    "\n",
    "\n",
    "def unstack_and_split(x, batch_size, num_channels=3):\n",
    "  \"\"\"Unstack batch dimension and split into channels and alpha mask.\"\"\"\n",
    "  unstacked = tf.reshape(x, [batch_size, -1] + x.shape.as_list()[1:])\n",
    "  channels, masks = tf.split(unstacked, [num_channels, 1], axis=-1)\n",
    "  return channels, masks\n",
    "    \n",
    "\n",
    "def build_grid(resolution):\n",
    "  ranges = [np.linspace(0., 1., num=res) for res in resolution]\n",
    "  grid = np.meshgrid(*ranges, sparse=False, indexing=\"ij\")\n",
    "  grid = np.stack(grid, axis=-1)\n",
    "  grid = np.reshape(grid, [resolution[0], resolution[1], -1])\n",
    "  grid = np.expand_dims(grid, axis=0)\n",
    "  grid = grid.astype(np.float32)\n",
    "  return np.concatenate([grid, 1.0 - grid], axis=-1)\n",
    "\n",
    "\n",
    "class SoftPositionEmbed(layers.Layer):\n",
    "  \"\"\"Adds soft positional embedding with learnable projection.\"\"\"\n",
    "\n",
    "  def __init__(self, hidden_size, resolution):\n",
    "    \"\"\"Builds the soft position embedding layer.\n",
    "    Args:\n",
    "      hidden_size: Size of input feature dimension.\n",
    "      resolution: Tuple of integers specifying width and height of grid.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self.dense = layers.Dense(hidden_size, use_bias=True)\n",
    "    self.grid = build_grid(resolution)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.dense(self.grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-18 14:35:42.441400: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-18 14:35:42.441786: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "resolution = (256,256)\n",
    "num_slots = 7\n",
    "num_iterations = 3\n",
    "\n",
    "encoder_cnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=5, padding=\"SAME\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=5, padding=\"SAME\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=5, padding=\"SAME\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=5, padding=\"SAME\", activation=\"relu\")\n",
    "], name=\"encoder_cnn\")\n",
    "\n",
    "decoder_initial_size = (8, 8)\n",
    "decoder_cnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2DTranspose(64, 5, strides=(2, 2), padding=\"SAME\", activation=\"relu\"),  \n",
    "    tf.keras.layers.Conv2DTranspose(64, 5, strides=(2, 2), padding=\"SAME\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2DTranspose(64, 5, strides=(2, 2), padding=\"SAME\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2DTranspose(64, 5, strides=(2, 2), padding=\"SAME\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2DTranspose(64, 5, strides=(2, 2), padding=\"SAME\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2DTranspose(4, 3, strides=(1, 1), padding=\"SAME\", activation=None)\n",
    "], name=\"decoder_cnn\")\n",
    "\n",
    "encoder_pos = SoftPositionEmbed(64, resolution)\n",
    "decoder_pos = SoftPositionEmbed(64, decoder_initial_size)\n",
    "\n",
    "layer_norm = tf.keras.layers.LayerNormalization()\n",
    "mlp = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(64)\n",
    "], name=\"encoded_feedforward\")\n",
    "\n",
    "slot_attention = SlotAttention(num_iterations=num_iterations, num_slots=num_slots, slot_size=64, mlp_hidden_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Slot_Attention_AutoEnconder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " encoder_cnn (Sequential)       (None, 256, 256, 64  312256      ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " soft_position_embed (SoftPosit  (None, 256, 256, 64  320        ['encoder_cnn[0][0]']            \n",
      " ionEmbed)                      )                                                                 \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)        (None, 65536, 64)    0           ['soft_position_embed[0][0]']    \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 65536, 64)   128         ['tf.reshape[0][0]']             \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " encoded_feedforward (Sequentia  (None, 65536, 64)   8320        ['layer_normalization[0][0]']    \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " slot_attention (SlotAttention)  (None, 7, 64)       54336       ['encoded_feedforward[0][0]']    \n",
      "                                                                                                  \n",
      " tf.reshape_1 (TFOpLambda)      (None, 64)           0           ['slot_attention[0][0]']         \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 1, 1, 64)    0           ['tf.reshape_1[0][0]']           \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.tile (TFOpLambda)           (None, 8, 8, 64)     0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " soft_position_embed_1 (SoftPos  (None, 8, 8, 64)    320         ['tf.tile[0][0]']                \n",
      " itionEmbed)                                                                                      \n",
      "                                                                                                  \n",
      " decoder_cnn (Sequential)       (None, 256, 256, 4)  514628      ['soft_position_embed_1[0][0]']  \n",
      "                                                                                                  \n",
      " tf.reshape_2 (TFOpLambda)      (64, None, 256, 256  0           ['decoder_cnn[0][0]']            \n",
      "                                , 4)                                                              \n",
      "                                                                                                  \n",
      " tf.split (TFOpLambda)          [(64, None, 256, 25  0           ['tf.reshape_2[0][0]']           \n",
      "                                6, 3),                                                            \n",
      "                                 (64, None, 256, 25                                               \n",
      "                                6, 1)]                                                            \n",
      "                                                                                                  \n",
      " tf.nn.softmax (TFOpLambda)     (64, None, 256, 256  0           ['tf.split[0][1]']               \n",
      "                                , 1)                                                              \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (64, None, 256, 256  0           ['tf.split[0][0]',               \n",
      "                                , 3)                              'tf.nn.softmax[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  (64, 256, 256, 3)   0           ['tf.math.multiply[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 890,308\n",
      "Trainable params: 890,308\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# `image` has shape: [batch_size, width, height, num_channels].\n",
    "\n",
    "# Convolutional encoder with position embedding.\n",
    "inputs = tf.keras.Input(shape=(256,256,3,))\n",
    "x = encoder_cnn(inputs)  # CNN Backbone.\n",
    "x = encoder_pos(x)  # Add positional embeddings to x\n",
    "x = spatial_flatten(x)  # Flatten spatial dimensions (treat image as set).\n",
    "x = mlp(layer_norm(x))  # Feedforward network on set.\n",
    "# `x` has shape: [batch_size, width*height, input_size(64)].\n",
    "\n",
    "# Slot Attention module.\n",
    "slots = slot_attention(x)\n",
    "# `slots` has shape: [batch_size, num_slots, slot_size].\n",
    "\n",
    "# Spatial broadcast decoder.\n",
    "x = spatial_broadcast(slots, decoder_initial_size)\n",
    "# `x` has shape: [batch_size*num_slots, width_init, height_init, slot_size].\n",
    "x = decoder_pos(x)\n",
    "x = decoder_cnn(x)\n",
    "# `x` has shape: [batch_size*num_slots, width, height, num_channels+1].\n",
    "\n",
    "# Undo combination of slot and batch dimension; split alpha masks.\n",
    "recons, masks = unstack_and_split(x, batch_size=64)\n",
    "# `recons` has shape: [batch_size, num_slots, width, height, num_channels].\n",
    "# `masks` has shape: [batch_size, num_slots, width, height, 1].\n",
    "\n",
    "# Normalize alpha masks over slots.\n",
    "masks = tf.nn.softmax(masks, axis=1)\n",
    "recon_combined = tf.reduce_sum(recons * masks, axis=1)  # Recombine image.\n",
    "# `recon_combined` has shape: [batch_size, width, height, num_channels].\n",
    "\n",
    "outputs = recon_combined, recons, masks, slots\n",
    "\n",
    "slot_attention_ae = tf.keras.Model(inputs = inputs, outputs = outputs, name=\"Slot_Attention_AutoEnconder\")\n",
    "slot_attention_ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading manifest: 100%|███████████████████| 179067/179067 [00:02<00:00, 60.1k/s]\n",
      "100%|██████████████████████████████████████| 9.34k/9.34k [00:02<00:00, 3.94kB/s]\n",
      "100%|██████████████████████████████████████| 11.9k/11.9k [00:03<00:00, 3.83kB/s]\n",
      "100%|██████████████████████████████████████| 11.5k/11.5k [00:02<00:00, 4.96kB/s]\n",
      "100%|██████████████████████████████████████| 6.92k/6.92k [00:02<00:00, 2.96kB/s]\n",
      "100%|██████████████████████████████████████| 11.6k/11.6k [00:02<00:00, 4.81kB/s]\n",
      "100%|██████████████████████████████████████| 13.1k/13.1k [00:02<00:00, 5.15kB/s]\n",
      "100%|██████████████████████████████████████| 10.2k/10.2k [00:02<00:00, 3.98kB/s]\n",
      "100%|██████████████████████████████████████| 10.8k/10.8k [00:02<00:00, 4.70kB/s]\n",
      "100%|██████████████████████████████████████| 4.26k/4.26k [00:02<00:00, 1.66kB/s]\n",
      "100%|██████████████████████████████████████| 7.30k/7.30k [00:02<00:00, 3.17kB/s]\n",
      "100%|██████████████████████████████████████| 8.37k/8.37k [00:02<00:00, 3.51kB/s]\n",
      "100%|██████████████████████████████████████| 6.66k/6.66k [00:02<00:00, 2.87kB/s]\n",
      "100%|██████████████████████████████████████| 6.79k/6.79k [00:03<00:00, 2.13kB/s]\n",
      "100%|██████████████████████████████████████| 12.7k/12.7k [00:02<00:00, 5.48kB/s]\n",
      "100%|██████████████████████████████████████| 9.35k/9.35k [00:02<00:00, 3.92kB/s]\n",
      "100%|██████████████████████████████████████| 12.2k/12.2k [00:02<00:00, 5.28kB/s]\n",
      "100%|██████████████████████████████████████| 10.2k/10.2k [00:02<00:00, 4.22kB/s]\n",
      "100%|██████████████████████████████████████| 8.08k/8.08k [00:02<00:00, 3.27kB/s]\n",
      "100%|██████████████████████████████████████| 7.52k/7.52k [00:02<00:00, 2.96kB/s]\n",
      "100%|██████████████████████████████████████| 8.72k/8.72k [00:02<00:00, 3.59kB/s]\n",
      "100%|██████████████████████████████████████| 6.53k/6.53k [00:02<00:00, 2.84kB/s]\n",
      "100%|██████████████████████████████████████| 10.4k/10.4k [00:02<00:00, 4.37kB/s]\n",
      "100%|██████████████████████████████████████| 12.2k/12.2k [00:02<00:00, 5.32kB/s]\n",
      "100%|██████████████████████████████████████| 7.11k/7.11k [00:02<00:00, 2.86kB/s]\n",
      "100%|██████████████████████████████████████| 9.55k/9.55k [00:02<00:00, 3.87kB/s]\n",
      "100%|██████████████████████████████████████| 5.91k/5.91k [00:02<00:00, 2.39kB/s]\n",
      "100%|██████████████████████████████████████| 5.93k/5.93k [00:02<00:00, 2.56kB/s]\n",
      "100%|██████████████████████████████████████| 9.18k/9.18k [00:02<00:00, 3.56kB/s]\n",
      "100%|██████████████████████████████████████| 6.73k/6.73k [00:02<00:00, 2.92kB/s]\n",
      "100%|██████████████████████████████████████| 10.1k/10.1k [00:02<00:00, 4.33kB/s]\n",
      "100%|██████████████████████████████████████| 7.44k/7.44k [00:02<00:00, 3.23kB/s]\n",
      "100%|██████████████████████████████████████| 8.83k/8.83k [00:02<00:00, 3.60kB/s]\n",
      "100%|██████████████████████████████████████| 13.1k/13.1k [00:02<00:00, 5.24kB/s]\n",
      "100%|██████████████████████████████████████| 12.1k/12.1k [00:02<00:00, 4.03kB/s]\n",
      "100%|██████████████████████████████████████| 6.99k/6.99k [00:02<00:00, 3.04kB/s]\n",
      "100%|██████████████████████████████████████| 8.38k/8.38k [00:02<00:00, 3.51kB/s]\n",
      "100%|██████████████████████████████████████| 9.22k/9.22k [00:02<00:00, 3.93kB/s]\n",
      "100%|██████████████████████████████████████| 9.81k/9.81k [00:02<00:00, 4.12kB/s]\n",
      "100%|██████████████████████████████████████| 7.12k/7.12k [00:02<00:00, 2.88kB/s]\n",
      "100%|██████████████████████████████████████| 12.3k/12.3k [00:02<00:00, 5.10kB/s]\n",
      "100%|██████████████████████████████████████| 9.00k/9.00k [00:02<00:00, 3.63kB/s]\n",
      "100%|██████████████████████████████████████| 9.28k/9.28k [00:02<00:00, 3.99kB/s]\n",
      "100%|██████████████████████████████████████| 6.06k/6.06k [00:02<00:00, 2.49kB/s]\n",
      "100%|██████████████████████████████████████| 7.99k/7.99k [00:02<00:00, 3.39kB/s]\n",
      "100%|██████████████████████████████████████| 6.37k/6.37k [00:02<00:00, 2.63kB/s]\n",
      "100%|██████████████████████████████████████| 5.72k/5.72k [00:02<00:00, 2.47kB/s]\n",
      "100%|██████████████████████████████████████| 6.77k/6.77k [00:02<00:00, 2.84kB/s]\n",
      "100%|██████████████████████████████████████| 11.1k/11.1k [00:02<00:00, 4.46kB/s]\n",
      "100%|██████████████████████████████████████| 8.33k/8.33k [00:02<00:00, 3.51kB/s]\n",
      "100%|██████████████████████████████████████| 11.8k/11.8k [00:02<00:00, 4.80kB/s]\n",
      "100%|██████████████████████████████████████| 8.40k/8.40k [00:02<00:00, 3.66kB/s]\n",
      "100%|██████████████████████████████████████| 10.4k/10.4k [00:02<00:00, 4.09kB/s]\n",
      "100%|██████████████████████████████████████| 8.02k/8.02k [00:02<00:00, 3.46kB/s]\n",
      "100%|██████████████████████████████████████| 13.1k/13.1k [00:02<00:00, 5.62kB/s]\n",
      "100%|██████████████████████████████████████| 11.2k/11.2k [00:03<00:00, 3.64kB/s]\n",
      "100%|██████████████████████████████████████| 6.53k/6.53k [00:02<00:00, 2.67kB/s]\n",
      "100%|██████████████████████████████████████| 10.1k/10.1k [00:02<00:00, 4.38kB/s]\n",
      "100%|██████████████████████████████████████| 7.17k/7.17k [00:02<00:00, 2.93kB/s]\n",
      "100%|██████████████████████████████████████| 11.1k/11.1k [00:02<00:00, 4.79kB/s]\n",
      "100%|██████████████████████████████████████| 14.6k/14.6k [00:02<00:00, 5.81kB/s]\n",
      "100%|██████████████████████████████████████| 17.4k/17.4k [00:02<00:00, 6.73kB/s]\n",
      "100%|██████████████████████████████████████| 7.63k/7.63k [00:02<00:00, 3.18kB/s]\n",
      "100%|██████████████████████████████████████| 10.2k/10.2k [00:02<00:00, 4.10kB/s]\n",
      "100%|██████████████████████████████████████| 6.76k/6.76k [00:02<00:00, 2.81kB/s]\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import tifffile\n",
    "import quilt3 as q3\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from aicsimageio import AICSImage #=> this package was really difficult to install, maybe using an automated yaml would be good\n",
    "from PIL import Image\n",
    "import os\n",
    "from urllib.parse import urlparse, unquote\n",
    "\n",
    "pipeline = q3.Package.browse(\n",
    "    \"aics/pipeline_integrated_single_cell\",\n",
    "    registry=\"s3://allencell\"\n",
    ")\n",
    "\n",
    "def convert_to_padded_tensor(img):\n",
    "    image_tensor = tf.convert_to_tensor(img.data[0][0])\n",
    "    padded_tensor = tf.image.resize_with_crop_or_pad(image_tensor, 256, 256)\n",
    "    return padded_tensor\n",
    "\n",
    "batch = None\n",
    "\n",
    "imgs = []\n",
    "\n",
    "for ind, file_name in enumerate(pipeline[\"cell_images_2d\"]):\n",
    "    if (ind < 64):\n",
    "        entry = pipeline[\"cell_images_2d\"][file_name].fetch(f\"./AllenCell/{file_name}\")\n",
    "        uri_file_path = entry.get()\n",
    "        file_path = unquote(urlparse(uri_file_path).path) # => this is stupid because you literally define the path in the line above         img = AICSImage(file_path)\n",
    "        img = AICSImage(file_path)\n",
    "        #print(tf.convert_to_tensor(img.data[0][0]).shape)\n",
    "        \n",
    "        #imgs.append(img.data[0][0])\n",
    "        tensor = convert_to_padded_tensor(img)\n",
    "        imgs.append(tensor[0])\n",
    "        \n",
    "        #if batch == None:\n",
    "            #batch = tensor\n",
    "        #else:\n",
    "            #batch = tf.concat([batch, tensor], axis=0)\n",
    "        \n",
    "#print(batch.shape)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]]],\n",
       " \n",
       " \n",
       "        [[[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]]],\n",
       " \n",
       " \n",
       "        [[[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]]],\n",
       " \n",
       " \n",
       "        [[[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]]],\n",
       " \n",
       " \n",
       "        [[[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]]]], dtype=uint8)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.batch(64)\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in dataset:\n",
    "    slot_attention_ae(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G5j9ZfBpeNa3",
    "outputId": "baae4701-4c3e-4700-b008-f2532dbdee0c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Training loop for object discovery with Slot Attention.\"\"\"\n",
    "\n",
    "# We use `tf.function` compilation to speed up execution. For debugging,\n",
    "# consider commenting out the `@tf.function` decorator.\n",
    "\n",
    "\n",
    "def l2_loss(prediction, target):\n",
    "  return tf.reduce_mean(tf.math.squared_difference(prediction, target))\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(batch, model, optimizer):\n",
    "  \"\"\"Perform a single training step.\"\"\"\n",
    "\n",
    "  # Get the prediction of the models and compute the loss.\n",
    "  with tf.GradientTape() as tape:\n",
    "    preds = model(batch[\"image\"], training=True)\n",
    "    recon_combined, recons, masks, slots = preds\n",
    "    loss_value = l2_loss(recon_combined, batch[\"image\"])\n",
    "    del recons, masks, slots  # Unused.\n",
    "\n",
    "  # Get and apply gradients.\n",
    "  gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_weights))   \n",
    "\n",
    "  return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loss(losses): \n",
    "    \"\"\"\n",
    "    Uses Matplotlib to visualize the losses of our model.\n",
    "    :param losses: list of loss data stored from train. Can use the model's loss_list \n",
    "    field \n",
    "\n",
    "    NOTE: DO NOT EDIT\n",
    "\n",
    "    :return: doesn't return anything, a plot should pop-up \n",
    "    \"\"\"\n",
    "    x = [i for i in range(len(losses))]\n",
    "    plt.plot(x, losses)\n",
    "    plt.title('Loss per epoch')\n",
    "    plt.xlabel('Training Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 15:47:29.353231: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-09-16 15:47:29.353342: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 15:47:29.580398: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "Training Epochs:   0%|                                 | 0/5000 [00:00<?, ?it/s]2022-09-16 15:47:31.000186: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "Training Epochs:   0%|                     | 24/5000 [03:07<11:04:06,  8.01s/it]"
     ]
    }
   ],
   "source": [
    "# Hyperparameters of the model.\n",
    "batch_size = 64\n",
    "num_slots = 7\n",
    "num_iterations = 3\n",
    "base_learning_rate = 0.0004\n",
    "num_train_steps = 5000\n",
    "warmup_steps = 5\n",
    "decay_rate = 0.5\n",
    "decay_steps = 100000\n",
    "tf.random.set_seed(0)\n",
    "resolution = (128, 128)\n",
    "\n",
    "# Build dataset iterators, optimizers and model.\n",
    "data_iterator = build_clevr_iterator(\n",
    "    batch_size, split=\"train\", resolution=resolution, shuffle=True,\n",
    "    max_n_objects=6, get_properties=False, apply_crop=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(base_learning_rate, epsilon=1e-08)\n",
    "\n",
    "model = build_model(resolution, batch_size, num_slots,\n",
    "                    num_iterations, model_type=\"object_discovery\")\n",
    "  \n",
    "# Prepare checkpoint manager.\n",
    "global_step = tf.Variable(\n",
    "    0, trainable=False, name=\"global_step\", dtype=tf.int64)\n",
    "\n",
    "losses = []\n",
    "\n",
    "for _ in tqdm(range(num_train_steps), desc='Training Epochs'):\n",
    "    batch = next(data_iterator)\n",
    "\n",
    "    # Learning rate warm-up.\n",
    "    if global_step < warmup_steps:\n",
    "      learning_rate = base_learning_rate * tf.cast(\n",
    "          global_step, tf.float32) / tf.cast(warmup_steps, tf.float32)\n",
    "    else:\n",
    "      learning_rate = base_learning_rate\n",
    "    \n",
    "    learning_rate = learning_rate * (decay_rate ** (\n",
    "        tf.cast(global_step, tf.float32) / tf.cast(decay_steps, tf.float32)))\n",
    "    optimizer.lr = learning_rate.numpy()\n",
    "\n",
    "    loss_value = train_step(batch, model, optimizer)\n",
    "    losses.append(loss_value)\n",
    "\n",
    "    # Update the global step. We update it before logging the loss and saving\n",
    "    # the model so that the last checkpoint is saved at the last iteration.\n",
    "    global_step.assign_add(1)\n",
    "    \n",
    "visualize_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1PWP4Q77v9k"
   },
   "outputs": [],
   "source": [
    "def renormalize(x):\n",
    "  \"\"\"Renormalize from [-1, 1] to [0, 1].\"\"\"\n",
    "  return x / 2. + 0.5\n",
    "\n",
    "def get_prediction(model, batch, idx=0):\n",
    "  recon_combined, recons, masks, slots = model(batch[\"image\"])\n",
    "  image = renormalize(batch[\"image\"])[idx]\n",
    "  recon_combined = renormalize(recon_combined)[idx]\n",
    "  recons = renormalize(recons)[idx]\n",
    "  masks = masks[idx]\n",
    "  return image, recon_combined, recons, masks, slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4bhXod7Q7xXB"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "resolution = (128,128)\n",
    "data_iterator = build_clevr_iterator(\n",
    "    batch_size, split=\"validation\", resolution=resolution, shuffle=True,\n",
    "    max_n_objects=6, get_properties=False, apply_crop=True)\n",
    "\n",
    "batch = next(data_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize.\n",
    "plt.imshow(renormalize(batch[\"image\"])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzJouS6a7yvZ"
   },
   "outputs": [],
   "source": [
    "image, recon_combined, recons, masks, slots = get_prediction(model, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize.\n",
    "num_slots = len(masks)\n",
    "fig, ax = plt.subplots(1, num_slots + 2, figsize=(15, 2))\n",
    "ax[0].imshow(image)\n",
    "ax[0].set_title('Image')\n",
    "ax[1].imshow(recon_combined)\n",
    "ax[1].set_title('Recon.')\n",
    "for i in range(num_slots):\n",
    "  ax[i + 2].imshow(recons[i] * masks[i] + (1 - masks[i]))\n",
    "  ax[i + 2].set_title('Slot %s' % str(i + 1))\n",
    "for i in range(len(ax)):\n",
    "  ax[i].grid(False)\n",
    "  ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(recon_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(masks[1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Slot Attention.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9 (Slot Attention)",
   "language": "python",
   "name": "slotattention"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
