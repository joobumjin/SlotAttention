{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "iTGnEyGT7m0s"
   },
   "outputs": [],
   "source": [
    "from absl import logging\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import numpy as np\n",
    "import tensorflow.keras.layers as layers\n",
    "from tqdm import tqdm\n",
    "\n",
    "import io\n",
    "import tifffile\n",
    "import quilt3 as q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aics/actk',\n",
       " 'aics/aics_mnist',\n",
       " 'aics/cell_line_exomes',\n",
       " 'aics/cell_line_rnaseq',\n",
       " 'aics/data_handoff_4dn',\n",
       " 'aics/hipsc_12x_overview_image_dataset',\n",
       " 'aics/hipsc_single_cell_image_dataset',\n",
       " 'aics/hipsc_single_cell_image_dataset_supp_myh10',\n",
       " 'aics/hipsc_single_edge_cell_image_dataset',\n",
       " 'aics/hipsc_single_i1_cell_image_dataset',\n",
       " 'aics/hipsc_single_i2_cell_image_dataset',\n",
       " 'aics/hipsc_single_m1_cell_image_dataset',\n",
       " 'aics/hipsc_single_m2_cell_image_dataset',\n",
       " 'aics/hipsc_single_nonedge_cell_image_dataset',\n",
       " 'aics/integrated_transcriptomics_structural_organization_hipsc_cm',\n",
       " 'aics/label-free-imaging-collection',\n",
       " 'aics/laminb1_sample_data',\n",
       " 'aics/mitotic_annotation',\n",
       " 'aics/nuclear_project_dataset_1',\n",
       " 'aics/nuclear_project_dataset_2',\n",
       " 'aics/nuclear_project_dataset_3',\n",
       " 'aics/nuclear_project_dataset_4',\n",
       " 'aics/pipeline_integrated_cell',\n",
       " 'aics/pipeline_integrated_single_cell',\n",
       " 'aics/segmenter_model_zoo',\n",
       " 'aics/wtc11_hipsc_cardiomyocyte_scrnaseq_d0_to_d90',\n",
       " 'aics/wtc11_linkedread_wgs',\n",
       " 'aics/wtc11_short_read_genome_sequence',\n",
       " 'test/tmp']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(q3.list_packages(\"s3://allencell\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading manifest: 100%|████████████████| 16.4M/16.4M [00:03<00:00, 4.87MB/s]\n",
      "Loading manifest: 100%|█████████████████████| 49342/49342 [00:00<00:00, 95.3k/s]\n"
     ]
    }
   ],
   "source": [
    "label_free = q3.Package.browse(\n",
    "    \"aics/label-free-imaging-collection\",\n",
    "    registry=\"s3://allencell\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "imread_bytes = lambda b: tifffile.TiffFile(io.BytesIO(b)).asarray()\n",
    "img = label_free[\"cells_2d\"][\"fov-0_CellIndex-12.tiff\"](imread_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading manifest: 100%|███████████████████| 484465/484465 [00:07<00:00, 67.4k/s]\n"
     ]
    }
   ],
   "source": [
    "single_cell = q3.Package.browse(\n",
    "    \"aics/hipsc_single_cell_image_dataset\",\n",
    "    registry=\"s3://allencell\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = single_cell[\"crop_raw\"][\"00011451c65b106cf9889bbf78cb4aa2cf2f9ec56c681e50fafc9635c3abf752_raw.ome.tif\"](imread_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(remote Package)\n",
       " └─00011451c65b106cf9889bbf78cb4aa2cf2f9ec56c681e50fafc9635c3abf752_raw.ome.tif\n",
       " └─000136c32c54c3b33df562be1b916e2cab0d8437300f518866e6c03610750537_raw.ome.tif\n",
       " └─000140defc56a56ebee268271d648f24d46063027820245958398f0624fcdcf1_raw.ome.tif\n",
       " └─000154c959b7e87877adc131cf39b11a5796bc4acea133ce1f3eac41644ca151_raw.ome.tif\n",
       " └─0001c532d46d0e30e12de1309a1818db5e8cd3b144f4045f36482576516d7d83_raw.ome.tif\n",
       " └─00023fa497761bbbd6b6d84f5a36f1e01657c6ef6bfff133d1793491f7608bb6_raw.ome.tif\n",
       " └─00025dc4c230e2127264cfc7d185214f984dfd96c3c91e710952fe28ff6a378d_raw.ome.tif\n",
       " └─0002640e3a5b33df576a073a911ed32b9049e58a3e8ec612702798b6ac8ce128_raw.ome.tif\n",
       " └─00026e522e6d632e983b578eeee9d0ad46b7d6f36efd4b6a840387f8a765e917_raw.ome.tif\n",
       " └─0002c87bd63e09cbf5ff08d4a166af65992a8fba86a3df0f56c3b92ab38b20c1_raw.ome.tif\n",
       " └─0002f8ddaabd5e9aba9691a242c68b1ff93a708cb0e7c50df56f40ae2721cacb_raw.ome.tif\n",
       " └─00034a489693ec3e18f2aaffc50a1cdf01d8a055059fc55e6447aebdb1b4cd99_raw.ome.tif\n",
       " └─0003554ed3b1cf872bc881cc310631c0eb1a3d0899d83087e37bfca6c2edb8ef_raw.ome.tif\n",
       " └─00038c1beb8346f877d2c63b5c40cc82f4bd881840d567889b4278ef13831750_raw.ome.tif\n",
       " └─000396d156324facc026b7cf662a99dfb968be77779f5b8a4855dd9ba736899c_raw.ome.tif\n",
       " └─0003beb5242d4b0c3886500c5d2e2b73bb52fc436c495a163a092f0f89d79550_raw.ome.tif\n",
       " └─00046217406d416c2d44f461093744844f72e91d86137662fc5fcf8f9b17b64b_raw.ome.tif\n",
       " └─00048f6ee817214992ed328ee8f16ec112b7b56ec30ae6893aeac68f4eb2e9ea_raw.ome.tif\n",
       " └─0004ec40f3e1a4180ad13636beb6046a9df2d385f56760650b033285edbe7090_raw.ome.tif\n",
       " └─00054e759e20d5c18f7714ab9b39b6295708b0876884bbb4e74d43f8b4a6c61e_raw.ome.tif\n",
       " ..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_cell[\"crop_raw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 3, 274, 297)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2d01ce550>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YgnYaJ67cjgW"
   },
   "outputs": [],
   "source": [
    "def preprocess_clevr(features, resolution, apply_crop=False,\n",
    "                     get_properties=True, max_n_objects=10):\n",
    "  \"\"\"Preprocess CLEVR.\"\"\"\n",
    "  image = tf.cast(features[\"image\"], dtype=tf.float32)\n",
    "  image = ((image / 255.0) - 0.5) * 2.0  # Rescale to [-1, 1].\n",
    "\n",
    "  image = tf.image.resize(\n",
    "      image, resolution, method=tf.image.ResizeMethod.BILINEAR)\n",
    "  image = tf.clip_by_value(image, -1., 1.)\n",
    "    \n",
    "  features = {\"image\": image}\n",
    "  return features\n",
    "\n",
    "\n",
    "def build_clevr(split, resolution=(128, 128), shuffle=False, max_n_objects=10,\n",
    "                num_eval_examples=512, apply_crop=False):\n",
    "  \"\"\"Build CLEVR dataset.\"\"\"\n",
    "  if split == \"train\" or split == \"train_eval\":\n",
    "    ds = tfds.load(\"clevr:3.1.0\", split=\"train\", shuffle_files=shuffle)\n",
    "    if split == \"train\":\n",
    "      ds = ds.skip(num_eval_examples)\n",
    "    elif split == \"train_eval\":\n",
    "      # Instead of taking the official validation split, we take a smaller split\n",
    "      # from the training dataset to monitor AP scores during training.\n",
    "      ds = ds.take(num_eval_examples)\n",
    "  else:\n",
    "    ds = tfds.load(\"clevr:3.1.0\", split=split, shuffle_files=shuffle)\n",
    "\n",
    "  def _preprocess_fn(x, resolution, max_n_objects=max_n_objects):\n",
    "    return preprocess_clevr(\n",
    "        x, resolution, apply_crop=apply_crop, get_properties=get_properties,\n",
    "        max_n_objects=max_n_objects)\n",
    "  ds = ds.map(lambda x: _preprocess_fn(x, resolution))\n",
    "  return ds\n",
    "\n",
    "\n",
    "def build_clevr_iterator(batch_size, split, **kwargs):\n",
    "  ds = build_clevr(split=split, **kwargs)\n",
    "  ds = ds.repeat(-1)\n",
    "  ds = ds.batch(batch_size, drop_remainder=True)\n",
    "  return iter(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fTdux-_354b7"
   },
   "outputs": [],
   "source": [
    "\"\"\"Slot Attention model for object discovery and set prediction.\"\"\"\n",
    "\n",
    "class SlotAttention(layers.Layer):\n",
    "  \"\"\"Slot Attention module.\"\"\"\n",
    "\n",
    "  def __init__(self, num_iterations, num_slots, slot_size, mlp_hidden_size,\n",
    "               epsilon=1e-8):\n",
    "    \"\"\"Builds the Slot Attention module.\n",
    "    Args:\n",
    "      num_iterations: Number of iterations.\n",
    "      num_slots: Number of slots.\n",
    "      slot_size: Dimensionality of slot feature vectors.\n",
    "      mlp_hidden_size: Hidden layer size of MLP.\n",
    "      epsilon: Offset for attention coefficients before normalization.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self.num_iterations = num_iterations\n",
    "    self.num_slots = num_slots\n",
    "    self.slot_size = slot_size\n",
    "    self.mlp_hidden_size = mlp_hidden_size\n",
    "    self.epsilon = epsilon\n",
    "\n",
    "    self.norm_inputs = layers.LayerNormalization()\n",
    "    self.norm_slots = layers.LayerNormalization()\n",
    "    self.norm_mlp = layers.LayerNormalization()\n",
    "\n",
    "    # Parameters for Gaussian init (shared by all slots).   # Intialize slots randomly at first \n",
    "    self.slots_mu = self.add_weight(\n",
    "        initializer=\"glorot_uniform\",\n",
    "        shape=[1, 1, self.slot_size],   # slot_size: Dimensionality of slot feature vectors.\n",
    "        dtype=tf.float32,\n",
    "        name=\"slots_mu\")\n",
    "    self.slots_log_sigma = self.add_weight(\n",
    "        initializer=\"glorot_uniform\",\n",
    "        shape=[1, 1, self.slot_size],\n",
    "        dtype=tf.float32,\n",
    "        name=\"slots_log_sigma\")\n",
    "\n",
    "    # Linear maps for the attention module.\n",
    "    self.project_q = layers.Dense(self.slot_size, use_bias=False, name=\"q\")\n",
    "    self.project_k = layers.Dense(self.slot_size, use_bias=False, name=\"k\")\n",
    "    self.project_v = layers.Dense(self.slot_size, use_bias=False, name=\"v\")\n",
    "\n",
    "    # Slot update functions.\n",
    "    self.gru = layers.GRUCell(self.slot_size)\n",
    "    self.mlp = tf.keras.Sequential([\n",
    "        layers.Dense(self.mlp_hidden_size, activation=\"relu\"),\n",
    "        layers.Dense(self.slot_size)\n",
    "    ], name=\"mlp\")\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # `inputs` has shape [batch_size, num_inputs, inputs_size].\n",
    "    inputs = self.norm_inputs(inputs)  # Apply layer norm to the input.\n",
    "    k = self.project_k(inputs)  # Shape: [batch_size, num_inputs, slot_size].  # create key vectors (based on inputs)\n",
    "    v = self.project_v(inputs)  # Shape: [batch_size, num_inputs, slot_size].  # create value vectors (based on inputs)\n",
    "\n",
    "    # Initialize the slots. Shape: [batch_size, num_slots, slot_size].\n",
    "    slots = self.slots_mu + tf.exp(self.slots_log_sigma) * tf.random.normal(\n",
    "        [tf.shape(inputs)[0], self.num_slots, self.slot_size])  # size: [batch_size, num_slots, slot_size]\n",
    "\n",
    "    # Multiple rounds of attention.\n",
    "    for _ in range(self.num_iterations):\n",
    "      slots_prev = slots\n",
    "      slots = self.norm_slots(slots)\n",
    "\n",
    "      # Attention.\n",
    "      q = self.project_q(slots)  # Shape: [batch_size, num_slots, slot_size].  # create query vectors (based on slots)\n",
    "      q *= self.slot_size ** -0.5  # Normalization.\n",
    "      attn_logits = tf.keras.backend.batch_dot(k, q, axes=-1) # Batchwise dot product.\n",
    "      attn = tf.nn.softmax(attn_logits, axis=-1)\n",
    "      # `attn` has shape: [batch_size, num_inputs, num_slots]. \n",
    "      # attn represents how much attention each slot should pay to the features \n",
    "\n",
    "      # Weigted mean.\n",
    "      attn += self.epsilon\n",
    "      attn /= tf.reduce_sum(attn, axis=-2, keepdims=True) # summation; sum across the batch_size \n",
    "      updates = tf.keras.backend.batch_dot(attn, v, axes=-2)\n",
    "      # `updates` has shape: [batch_size, num_slots, slot_size].\n",
    "\n",
    "      # Slot update.\n",
    "      slots, _ = self.gru(updates, [slots_prev])   # output after gru has shape: [batch_size, num_slots, slot_size]\n",
    "      slots += self.mlp(self.norm_mlp(slots))      # # output after mlp has shape: [batch_size, num_slots, slot_size]\n",
    "\n",
    "    return slots\n",
    "\n",
    "\n",
    "def spatial_broadcast(slots, resolution):\n",
    "  \"\"\"Broadcast slot features to a 2D grid and collapse slot dimension.\"\"\"\n",
    "  # `slots` has shape: [batch_size, num_slots, slot_size].\n",
    "  slots = tf.reshape(slots, [-1, slots.shape[-1]])[:, None, None, :]\n",
    "  grid = tf.tile(slots, [1, resolution[0], resolution[1], 1])   # this operation creates a new tensor by replicating input multiples times\n",
    "  # `grid` has shape: [batch_size*num_slots, width, height, slot_size].\n",
    "  return grid\n",
    "\n",
    "\n",
    "def spatial_flatten(x):\n",
    "  return tf.reshape(x, [-1, x.shape[1] * x.shape[2], x.shape[-1]])\n",
    "\n",
    "\n",
    "def unstack_and_split(x, batch_size, num_channels=3):\n",
    "  \"\"\"Unstack batch dimension and split into channels and alpha mask.\"\"\"\n",
    "  unstacked = tf.reshape(x, [batch_size, -1] + x.shape.as_list()[1:])\n",
    "  channels, masks = tf.split(unstacked, [num_channels, 1], axis=-1)\n",
    "  return channels, masks\n",
    "\n",
    "\n",
    "class SlotAttentionAutoEncoder(layers.Layer):\n",
    "  \"\"\"Slot Attention-based auto-encoder for object discovery.\"\"\"\n",
    "\n",
    "  def __init__(self, resolution, num_slots, num_iterations):\n",
    "    \"\"\"Builds the Slot Attention-based auto-encoder.\n",
    "    Args:\n",
    "      resolution: Tuple of integers specifying width and height of input image.\n",
    "      num_slots: Number of slots in Slot Attention.\n",
    "      num_iterations: Number of iterations in Slot Attention.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self.resolution = resolution\n",
    "    self.num_slots = num_slots\n",
    "    self.num_iterations = num_iterations\n",
    "\n",
    "    self.encoder_cnn = tf.keras.Sequential([\n",
    "        layers.Conv2D(64, kernel_size=5, padding=\"SAME\", activation=\"relu\"),\n",
    "        # kernel_size: An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. \n",
    "        # Can be a single integer to specify the same value for all spatial dimensions.\n",
    "        layers.Conv2D(64, kernel_size=5, padding=\"SAME\", activation=\"relu\"),\n",
    "        layers.Conv2D(64, kernel_size=5, padding=\"SAME\", activation=\"relu\"),\n",
    "        layers.Conv2D(64, kernel_size=5, padding=\"SAME\", activation=\"relu\")\n",
    "    ], name=\"encoder_cnn\")\n",
    "\n",
    "    self.decoder_initial_size = (8, 8)\n",
    "    self.decoder_cnn = tf.keras.Sequential([\n",
    "        layers.Conv2DTranspose(\n",
    "            64, 5, strides=(2, 2), padding=\"SAME\", activation=\"relu\"),  # filters = 64 (number of output channels); kernel_size = 5 (specify the height and width of the 2D convolution window)\n",
    "        layers.Conv2DTranspose(\n",
    "            64, 5, strides=(2, 2), padding=\"SAME\", activation=\"relu\"),\n",
    "        layers.Conv2DTranspose(\n",
    "            64, 5, strides=(2, 2), padding=\"SAME\", activation=\"relu\"),\n",
    "        layers.Conv2DTranspose(\n",
    "            64, 5, strides=(2, 2), padding=\"SAME\", activation=\"relu\"),\n",
    "        layers.Conv2DTranspose(\n",
    "            64, 5, strides=(1, 1), padding=\"SAME\", activation=\"relu\"),\n",
    "        layers.Conv2DTranspose(\n",
    "            4, 3, strides=(1, 1), padding=\"SAME\", activation=None)\n",
    "    ], name=\"decoder_cnn\")\n",
    "\n",
    "    self.encoder_pos = SoftPositionEmbed(64, self.resolution)\n",
    "    self.decoder_pos = SoftPositionEmbed(64, self.decoder_initial_size)\n",
    "\n",
    "    self.layer_norm = layers.LayerNormalization()\n",
    "    self.mlp = tf.keras.Sequential([\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(64)\n",
    "    ], name=\"feedforward\")\n",
    "\n",
    "    self.slot_attention = SlotAttention(\n",
    "        num_iterations=self.num_iterations,\n",
    "        num_slots=self.num_slots,\n",
    "        slot_size=64,\n",
    "        mlp_hidden_size=128)\n",
    "\n",
    "  def call(self, image):\n",
    "    # `image` has shape: [batch_size, width, height, num_channels].\n",
    "\n",
    "    # Convolutional encoder with position embedding.\n",
    "    x = self.encoder_cnn(image)  # CNN Backbone.\n",
    "    x = self.encoder_pos(x)  # Position embedding.\n",
    "    x = spatial_flatten(x)  # Flatten spatial dimensions (treat image as set).\n",
    "    x = self.mlp(self.layer_norm(x))  # Feedforward network on set.\n",
    "    # `x` has shape: [batch_size, width*height, input_size(64)].\n",
    "\n",
    "    # Slot Attention module.\n",
    "    slots = self.slot_attention(x)\n",
    "    # `slots` has shape: [batch_size, num_slots, slot_size].\n",
    "\n",
    "    # Spatial broadcast decoder.\n",
    "    x = spatial_broadcast(slots, self.decoder_initial_size)\n",
    "    # `x` has shape: [batch_size*num_slots, width_init, height_init, slot_size].\n",
    "    x = self.decoder_pos(x)\n",
    "    x = self.decoder_cnn(x)\n",
    "    # `x` has shape: [batch_size*num_slots, width, height, num_channels+1].\n",
    "\n",
    "    # Undo combination of slot and batch dimension; split alpha masks.\n",
    "    recons, masks = unstack_and_split(x, batch_size=image.shape[0])\n",
    "    # `recons` has shape: [batch_size, num_slots, width, height, num_channels].\n",
    "    # `masks` has shape: [batch_size, num_slots, width, height, 1].\n",
    "\n",
    "    # Normalize alpha masks over slots.\n",
    "    masks = tf.nn.softmax(masks, axis=1)\n",
    "    recon_combined = tf.reduce_sum(recons * masks, axis=1)  # Recombine image.\n",
    "    # `recon_combined` has shape: [batch_size, width, height, num_channels].\n",
    "\n",
    "    return recon_combined, recons, masks, slots\n",
    "    \n",
    "\n",
    "def build_grid(resolution):\n",
    "  ranges = [np.linspace(0., 1., num=res) for res in resolution]\n",
    "  grid = np.meshgrid(*ranges, sparse=False, indexing=\"ij\")\n",
    "  grid = np.stack(grid, axis=-1)\n",
    "  grid = np.reshape(grid, [resolution[0], resolution[1], -1])\n",
    "  grid = np.expand_dims(grid, axis=0)\n",
    "  grid = grid.astype(np.float32)\n",
    "  return np.concatenate([grid, 1.0 - grid], axis=-1)\n",
    "\n",
    "\n",
    "class SoftPositionEmbed(layers.Layer):\n",
    "  \"\"\"Adds soft positional embedding with learnable projection.\"\"\"\n",
    "\n",
    "  def __init__(self, hidden_size, resolution):\n",
    "    \"\"\"Builds the soft position embedding layer.\n",
    "    Args:\n",
    "      hidden_size: Size of input feature dimension.\n",
    "      resolution: Tuple of integers specifying width and height of grid.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self.dense = layers.Dense(hidden_size, use_bias=True)\n",
    "    self.grid = build_grid(resolution)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.dense(self.grid)\n",
    "\n",
    "\n",
    "def build_model(resolution, batch_size, num_slots, num_iterations,\n",
    "                num_channels=3, model_type=\"object_discovery\"):\n",
    "  \"\"\"Build keras model.\"\"\"\n",
    "  if model_type == \"object_discovery\":\n",
    "    model_def = SlotAttentionAutoEncoder\n",
    "  else:\n",
    "    raise ValueError(\"Invalid name for model type.\")\n",
    "\n",
    "  image = tf.keras.Input(list(resolution) + [num_channels], batch_size) # shape = list(resolution) + [num_channels]\n",
    "  outputs = model_def(resolution, num_slots, num_iterations)(image)  # initialize + call\n",
    "  model = tf.keras.Model(inputs=image, outputs=outputs)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G5j9ZfBpeNa3",
    "outputId": "baae4701-4c3e-4700-b008-f2532dbdee0c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Training loop for object discovery with Slot Attention.\"\"\"\n",
    "\n",
    "# We use `tf.function` compilation to speed up execution. For debugging,\n",
    "# consider commenting out the `@tf.function` decorator.\n",
    "\n",
    "\n",
    "def l2_loss(prediction, target):\n",
    "  return tf.reduce_mean(tf.math.squared_difference(prediction, target))\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(batch, model, optimizer):\n",
    "  \"\"\"Perform a single training step.\"\"\"\n",
    "\n",
    "  # Get the prediction of the models and compute the loss.\n",
    "  with tf.GradientTape() as tape:\n",
    "    preds = model(batch[\"image\"], training=True)\n",
    "    recon_combined, recons, masks, slots = preds\n",
    "    loss_value = l2_loss(recon_combined, batch[\"image\"])\n",
    "    del recons, masks, slots  # Unused.\n",
    "\n",
    "  # Get and apply gradients.\n",
    "  gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_weights))   \n",
    "\n",
    "  return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loss(losses): \n",
    "    \"\"\"\n",
    "    Uses Matplotlib to visualize the losses of our model.\n",
    "    :param losses: list of loss data stored from train. Can use the model's loss_list \n",
    "    field \n",
    "\n",
    "    NOTE: DO NOT EDIT\n",
    "\n",
    "    :return: doesn't return anything, a plot should pop-up \n",
    "    \"\"\"\n",
    "    x = [i for i in range(len(losses))]\n",
    "    plt.plot(x, losses)\n",
    "    plt.title('Loss per epoch')\n",
    "    plt.xlabel('Training Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 15:47:29.353231: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-09-16 15:47:29.353342: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 15:47:29.580398: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "Training Epochs:   0%|                                 | 0/5000 [00:00<?, ?it/s]2022-09-16 15:47:31.000186: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "Training Epochs:   0%|                     | 24/5000 [03:07<11:04:06,  8.01s/it]"
     ]
    }
   ],
   "source": [
    "# Hyperparameters of the model.\n",
    "batch_size = 64\n",
    "num_slots = 7\n",
    "num_iterations = 3\n",
    "base_learning_rate = 0.0004\n",
    "num_train_steps = 5000\n",
    "warmup_steps = 5\n",
    "decay_rate = 0.5\n",
    "decay_steps = 100000\n",
    "tf.random.set_seed(0)\n",
    "resolution = (128, 128)\n",
    "\n",
    "# Build dataset iterators, optimizers and model.\n",
    "data_iterator = build_clevr_iterator(\n",
    "    batch_size, split=\"train\", resolution=resolution, shuffle=True,\n",
    "    max_n_objects=6, get_properties=False, apply_crop=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(base_learning_rate, epsilon=1e-08)\n",
    "\n",
    "model = build_model(resolution, batch_size, num_slots,\n",
    "                    num_iterations, model_type=\"object_discovery\")\n",
    "  \n",
    "# Prepare checkpoint manager.\n",
    "global_step = tf.Variable(\n",
    "    0, trainable=False, name=\"global_step\", dtype=tf.int64)\n",
    "\n",
    "losses = []\n",
    "\n",
    "for _ in tqdm(range(num_train_steps), desc='Training Epochs'):\n",
    "    batch = next(data_iterator)\n",
    "\n",
    "    # Learning rate warm-up.\n",
    "    if global_step < warmup_steps:\n",
    "      learning_rate = base_learning_rate * tf.cast(\n",
    "          global_step, tf.float32) / tf.cast(warmup_steps, tf.float32)\n",
    "    else:\n",
    "      learning_rate = base_learning_rate\n",
    "    \n",
    "    learning_rate = learning_rate * (decay_rate ** (\n",
    "        tf.cast(global_step, tf.float32) / tf.cast(decay_steps, tf.float32)))\n",
    "    optimizer.lr = learning_rate.numpy()\n",
    "\n",
    "    loss_value = train_step(batch, model, optimizer)\n",
    "    losses.append(loss_value)\n",
    "\n",
    "    # Update the global step. We update it before logging the loss and saving\n",
    "    # the model so that the last checkpoint is saved at the last iteration.\n",
    "    global_step.assign_add(1)\n",
    "    \n",
    "visualize_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1PWP4Q77v9k"
   },
   "outputs": [],
   "source": [
    "def renormalize(x):\n",
    "  \"\"\"Renormalize from [-1, 1] to [0, 1].\"\"\"\n",
    "  return x / 2. + 0.5\n",
    "\n",
    "def get_prediction(model, batch, idx=0):\n",
    "  recon_combined, recons, masks, slots = model(batch[\"image\"])\n",
    "  image = renormalize(batch[\"image\"])[idx]\n",
    "  recon_combined = renormalize(recon_combined)[idx]\n",
    "  recons = renormalize(recons)[idx]\n",
    "  masks = masks[idx]\n",
    "  return image, recon_combined, recons, masks, slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4bhXod7Q7xXB"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "resolution = (128,128)\n",
    "data_iterator = build_clevr_iterator(\n",
    "    batch_size, split=\"validation\", resolution=resolution, shuffle=True,\n",
    "    max_n_objects=6, get_properties=False, apply_crop=True)\n",
    "\n",
    "batch = next(data_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize.\n",
    "plt.imshow(renormalize(batch[\"image\"])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzJouS6a7yvZ"
   },
   "outputs": [],
   "source": [
    "image, recon_combined, recons, masks, slots = get_prediction(model, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize.\n",
    "num_slots = len(masks)\n",
    "fig, ax = plt.subplots(1, num_slots + 2, figsize=(15, 2))\n",
    "ax[0].imshow(image)\n",
    "ax[0].set_title('Image')\n",
    "ax[1].imshow(recon_combined)\n",
    "ax[1].set_title('Recon.')\n",
    "for i in range(num_slots):\n",
    "  ax[i + 2].imshow(recons[i] * masks[i] + (1 - masks[i]))\n",
    "  ax[i + 2].set_title('Slot %s' % str(i + 1))\n",
    "for i in range(len(ax)):\n",
    "  ax[i].grid(False)\n",
    "  ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(recon_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(masks[1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Slot Attention.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
